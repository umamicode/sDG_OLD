{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8f8778-cdb6-4abe-8bbc-cca8e7f93f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/simclr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torchvision import models\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import os\n",
    "import click\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from loss_functions import SupConLoss, MdarLoss\n",
    "from network import mnist_net, res_net, cifar_net, generator\n",
    "from network.modules import get_resnet, get_generator, freeze, unfreeze, freeze_, unfreeze_, LARS\n",
    "from tools.miro_utils import *\n",
    "from tools.farmer import *\n",
    "import data_loader\n",
    "from main_base import evaluate\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84bffabb-bd3e-4ccb-8cfb-b9aef139f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06453d51-a9c5-46a2-a744-7d7d6df540a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_tgt= torch.rand(128,512)\n",
    "z_src= torch.rand(128,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3cb9aab-7f5a-4269-9bee-2918cd206384",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = nn.KLDivLoss(reduction=\"batchmean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9728fe48-9132-4463-8ab7-5ac9fab14487",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_tgt= torch.rand(128,512)\n",
    "z_src= torch.rand(128,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03dbff89-5fe2-4f89-a497-66e11e642f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.unsqueeze(z_src, dim=1)\n",
    "b= torch.unsqueeze(z_tgt, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80827147-a389-46fd-9f1f-f2c0122424f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm= nn.InstanceNorm2d(512, affine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6f62b99-0191-456c-91ae-564b373714e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= norm(a)\n",
    "b= norm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3fbc295-36c4-4991-a6a9-edf75cb3da29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.3795)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_loss(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f31c8db3-81e9-4c54-85f5-e7f55fe75671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "# input should be a distribution in the log space\n",
    "input = F.log_softmax(torch.randn(3, 5, requires_grad=True), dim=1)\n",
    "# Sample a batch of distributions. Usually this would come from the dataset\n",
    "target = F.softmax(torch.rand(3, 5), dim=1)\n",
    "output = kl_loss(input, target)\n",
    "\n",
    "kl_loss = nn.KLDivLoss(reduction=\"batchmean\", log_target=True)\n",
    "log_target = F.log_softmax(torch.rand(3, 5), dim=1)\n",
    "output = kl_loss(input, log_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b88d8-0c93-4d80-be59-2771ebb3e3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f2fc6-c910-4ceb-a8d7-c0fcb80adc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ea2196c-0d3a-4419-9cad-87d9aadec224",
   "metadata": {},
   "outputs": [],
   "source": [
    "features= torch.rand([16, 2, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "56b63aa4-b4cb-4974-99fb-01dbf9158cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class DomainLoss(nn.Module):\n",
    "    def __init__(self, projection_dim,device=None):\n",
    "        super(DomainLoss,self).__init__()\n",
    "        self.projection_dim= projection_dim\n",
    "        self.device= device\n",
    "        self.batch_size= None\n",
    "        self.norm = nn.InstanceNorm2d(projection_dim, affine=False)\n",
    "    def forward(self,features):\n",
    "        if self.device is not None:\n",
    "            device = self.device\n",
    "        else:\n",
    "            device = (torch.device('cuda')\n",
    "                      if features.is_cuda\n",
    "                      else torch.device('cpu'))\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
    "                             'at least 3 dimensions are required')\n",
    "        if len(features.shape) > 3:\n",
    "            features = features.view(features.shape[0], features.shape[1], -1)\n",
    "        self.batch_size = features.shape[0]\n",
    "        contrast_count = features.shape[1]\n",
    "        anchor_contrast_feature = torch.unbind(features, dim=1)\n",
    "        anchor_feature= anchor_contrast_feature[0]\n",
    "        contrast_feature= anchor_contrast_feature[1]\n",
    "        \n",
    "        #IN: remove instance specific information\n",
    "        anchor_feature=torch.unsqueeze(anchor_feature, dim=1) #(N,L)->(N,C,L)\n",
    "        contrast_feature=torch.unsqueeze(contrast_feature, dim=1) #(N,L)->(N,C,L)\n",
    "\n",
    "        anchor_feature= self.norm(anchor_feature)\n",
    "        contrast_feature= self.norm(contrast_feature)\n",
    "        \n",
    "        return 1/ (nn.KLDivLoss(reduction=\"batchmean\")(anchor_feature,contrast_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f6cc5560-e096-4e10-aa76-f7bb748652dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k= DomainLoss(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "95daa2e6-53fa-4020-9e03-f8a89b83aa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0678)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195cfbe-0f5b-4785-9801-97498f219a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
