{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e37a75-1fdd-4844-a4f1-5acf0f1c6c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/simclr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, USPS, SVHN, CIFAR10, STL10, ImageFolder\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "\n",
    "from tools.autoaugment import SVHNPolicy, CIFAR10Policy\n",
    "from tools.randaugment import RandAugment\n",
    "\n",
    "HOME = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "022140e8-954d-4749-94a7-ac7ed39545d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_officehome(split='train', translate=None, twox=False, ntr=None, autoaug=None, channels=3):\n",
    "    DIR_REALWORLD = './data/office_home/Real World'\n",
    "    trainpath= 'data/officehome-train.pkl'\n",
    "    testpath= 'data/officehome-test.pkl'\n",
    "    path = f'data/officehome-{split}.pkl'\n",
    "    officehome_convertor= {'train':trainpath, 'test':testpath}\n",
    "    officehome_transforms_train= transforms.Compose([transforms.Resize((224,224)),transforms.CenterCrop(224),transforms.ToTensor()]) #224,224\n",
    "    if not os.path.exists(path):\n",
    "        \n",
    "        dataset= ImageFolder(DIR_REALWORLD, transform=officehome_transforms_train)\n",
    "        \n",
    "        train_size = int(0.7 * len(dataset))\n",
    "        test_size = len(dataset) - train_size\n",
    "        train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "        \n",
    "        #Train Set\n",
    "        train_loader = torch.utils.data.DataLoader(train_set,batch_size=train_size,drop_last=True)\n",
    "        x, y= next(iter(train_loader))\n",
    "        x= torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "        with open(trainpath, 'wb') as f:\n",
    "            pickle.dump([x, y], f)\n",
    "        \n",
    "        #Test Set\n",
    "        test_loader = torch.utils.data.DataLoader(test_set,batch_size=test_size,drop_last=True, shuffle=True)\n",
    "        x, y= next(iter(test_loader))\n",
    "        x= torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "        with open(testpath, 'wb') as f:\n",
    "            pickle.dump([x, y], f) \n",
    "\n",
    "    with open(path, 'rb') as f:\n",
    "        x, y = pickle.load(f)\n",
    "        if channels == 1:\n",
    "            x = x[:,0:1,:,:]\n",
    "    \n",
    "    if ntr is not None:\n",
    "        x, y = x[0:ntr], y[0:ntr]\n",
    "    \n",
    "    # Without Data Augmentation\n",
    "    if (translate is None) and (autoaug is None):\n",
    "        dataset = TensorDataset(x, y)\n",
    "        return dataset\n",
    "    \n",
    "def load_officehome_domain(domain='Product', translate=None, twox=False, ntr=None, autoaug=None, channels=3):\n",
    "    DATASETS_NAMES = ['Art', 'Clipart', 'Product', 'Real World']\n",
    "    DIR_Art = './data/office_home/Art'\n",
    "    DIR_Clipart = './data/office_home/Clipart'\n",
    "    DIR_Product = './data/office_home/Product'\n",
    "    DIR_REALWORLD = './data/office_home/Real World'\n",
    "\n",
    "    path = f'data/officehome-{domain}.pkl'\n",
    "    #trainpath= 'data/officehome-train.pkl'\n",
    "    #testpath= 'data/officehome-test.pkl'\n",
    "\n",
    "    officehome_convertor= {'Art':DIR_Art, 'Clipart':DIR_Clipart,'Product':DIR_Product,'Real World':DIR_REALWORLD}\n",
    "    officehome_transforms_train= transforms.Compose([transforms.CenterCrop(224),transforms.Resize((224,224)),transforms.ToTensor()]) #224,224\n",
    "    if not os.path.exists(path):\n",
    "        \n",
    "        dataset= ImageFolder(officehome_convertor[domain], transform=officehome_transforms_train)\n",
    "        test_size = len(dataset)\n",
    "\n",
    "        #Test Set\n",
    "        test_loader = torch.utils.data.DataLoader(dataset,batch_size=test_size)\n",
    "        x, y= next(iter(test_loader))\n",
    "        x= torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump([x, y], f)\n",
    "\n",
    "    with open(path, 'rb') as f:\n",
    "        x, y = pickle.load(f)\n",
    "        if channels == 1:\n",
    "            x = x[:,0:1,:,:]\n",
    "    \n",
    "    if ntr is not None:\n",
    "        x, y = x[0:ntr], y[0:ntr]\n",
    "    \n",
    "    # Without Data Augmentation\n",
    "    if (translate is None) and (autoaug is None):\n",
    "        dataset = TensorDataset(x, y)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4d5cd4c-d0c6-438d-a9a7-e7e205615ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_officehome_domain(domain='Product', translate=None, twox=False, ntr=None, autoaug=None, channels=3):\n",
    "    DATASETS_NAMES = ['Art', 'Clipart', 'Product', 'Real World']\n",
    "    DIR_Art = './data/office_home/Art'\n",
    "    DIR_Clipart = './data/office_home/Clipart'\n",
    "    DIR_Product = './data/office_home/Product'\n",
    "    DIR_REALWORLD = './data/office_home/Real World'\n",
    "\n",
    "    path = f'data/officehome-{domain}.pkl'\n",
    "    #trainpath= 'data/officehome-train.pkl'\n",
    "    #testpath= 'data/officehome-test.pkl'\n",
    "\n",
    "    officehome_convertor= {'Art':DIR_Art, 'Clipart':DIR_Clipart,'Product':DIR_Product,'Real World':DIR_REALWORLD}\n",
    "    officehome_transforms_train= transforms.Compose([transforms.CenterCrop(224),transforms.Resize((224,224)),transforms.ToTensor()]) #224,224\n",
    "    if not os.path.exists(path):\n",
    "        \n",
    "        dataset= ImageFolder(officehome_convertor[domain], transform=officehome_transforms_train)\n",
    "        test_size = len(dataset)\n",
    "\n",
    "        #Test Set\n",
    "        test_loader = torch.utils.data.DataLoader(dataset,batch_size=test_size)\n",
    "        x, y= next(iter(test_loader))\n",
    "        x= torch.tensor(x)\n",
    "        y = torch.tensor(y)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump([x, y], f)\n",
    "\n",
    "    with open(path, 'rb') as f:\n",
    "        x, y = pickle.load(f)\n",
    "        if channels == 1:\n",
    "            x = x[:,0:1,:,:]\n",
    "    \n",
    "    if ntr is not None:\n",
    "        x, y = x[0:ntr], y[0:ntr]\n",
    "    \n",
    "    # Without Data Augmentation\n",
    "    if (translate is None) and (autoaug is None):\n",
    "        dataset = TensorDataset(x, y)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "907089c4-2cf9-4100-a46f-129ae0c1a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-ace56214efd7>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n",
      "<ipython-input-19-ace56214efd7>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y)\n",
      "<ipython-input-19-ace56214efd7>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x= torch.tensor(x)\n",
      "<ipython-input-19-ace56214efd7>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f81c860fbe0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_officehome('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b4b06-a24d-45d1-beac-49e64d987301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simclr",
   "language": "python",
   "name": "simclr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
